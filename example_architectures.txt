Example / Reference Architectures:

● FILE INTEGRITY MONITORING AT SCALE: (RSA Conf)
  REF: https://www.rsaconference.com/writable/presentations/file_upload/csv-r14-fim-and-system-call-auditing-at-scale-in-a-large-container-deployment.pdf
  KEYPOINT: AUDITING LOG TO GAIN INSIGHTS AT SCALE
  
                           ┌─> Pagerduty
              ┌─> Grafana ─┼─> Email
     Elastic  │            └─> Slack
     Search  ─┼─> Kibana
              │
              └─> Pre─processing ─> TensorFlow
  
  Alt1:

    User   │ go-audit-                          User space
    land   │ container                             app
    ───────├─────  Netlink ───── Syscall iface ───────────
    Kernel │        socket           ^
           │          ^              │
                      └─  Kauditd ───┘


● Adidas Reference Architecture:[[{testing.bdd,qa.documentation.api]]
Source @[https://adidas.github.io]
 └ UI:
   - Working with latest JS technologies ... building an stable ecosystem.
     analyzing and testing many framework.,
  
   - ... back in 2015 we used code which is better not to speak about,
     Now (2019), we use frameworks like React/Vue and modern tooling.
  
   - WEBPACK: DE-FACTO TOOL FOR SHIPPING APPLICATIONS: 
   
 └ API MANAGEMENT.  [[{api_management]]
   - APIARY: used for collaborative designing, documenting and governing
       API's helping to adopt API first approach with templates and best
       practices.
     - Out Platform is strongly integrated with our API guidelines, helping us
       to achieve consistency of all our API's.
     - Out Platform is strongly integrated with our API guidelines, helping us
     - speeds up and simplifies the development and testing phase by providing  [[qa.testing]]
       API mock services and automation of API testing.
  
   - MASHERY: delivers key API management capabilities.
     - Features include:
       API creation, packaging, testing, and management of your API's and
       community of users.
   - API SECURITY: provided via an embedded or optional on-premise API gateway.
 
   - RUNSCOPE: continuous monitoring platform for all our API's
     - It monitors uptime, performance and validates the data.
     - tightly integrated with Slack and Opsgenie in order to alert and
       create incident if things are going wrong way.
     - Runscope can quickly detect any issues with our API's [[qa.SLA]]
   [[}]]
  
 └ KAFKA: core of our "Fast Data Platform".
   - "... The more we work with it, the more versatile we perceived it was..."

   - Implement the pub-sub pattern in a very efficient way, enabling for: 
      - Data Streaming cases.
   - The fan-out is the pub-sub pattern is implemented in a really efficient
     way, allowing to achieve high thought in production and consumption.
  
   - It also enables capabilities like "Data Extraction" and "Data Modeling", 
     as long as Stateful Event Processing.

   - Together with STORM, Kafka STREAMS and ELK it provides the perfect toolset
     to integrate our digital applications in a modern self-service way.
  
 └ ACID: 
   - Jenkins: "de facto standard for continuous integration/continuous delivery".
   - ACID is a 100% docker powered by Kubernetes that allows to create 
     Jenkins-as-a-Service platform allowing for:
     - easy way to generate an isolated Jenkins environment per team while 
       while keeping a shared basic configuration and a central management dashboard.
  
 └ SerenityBDD: ACCEPTANCE+REGRESSION TESTING:
   - "Our default for automation in test solution".
   - Built on top of Selenium and Cucumber. 
   - provides archetypes for frontend (web) and backend (API).
  
 └ NEOLOAD: PERFORMANCE TESTING.
   - easy-to-use interface with powerful recording capabilities. 
   - supports for dockerized load generators.
  
 └ END-TO-END MONITORING:
   - Prometheus: alerting monitoring, completely integrated with Kubernetes.
   - ICINGA    : infrastructure monitoring.
     " we have hundreds of custom scripts and graphite as timeseries database".
   - Instana   : APM monitoring, making easy-and-fast to monitor the applications
                 and identify bottlenecks.
   - Runscope  : API testing-and-monitoring.
   - Grafana   : visualization tool.
     - Easy integration with with Prometheus, Instana, Elasticsearch, Graphite, etc.
   - LOGGING Collection and Monitoring:
     - ELK stack running on-premises and AWS Kubernetes.
       custom components for processing and alerting.     
     KEYPOINT: The goal of monitoring is troubleshooting. 
               all these tools have integration with Opsgenie
               where we have defined escalation policies for
               alerting and notifications. 
 - MOBILE STACK: "...Native is where we live..."
   - Kotlin for Android and Swift for iOS.
   - Build and testing: Jenkins and Fastlane.
[[}]]


● What a typical 100% Serverless Architecture  [[{01_PM.TODO]]
  looks like in AWS!
  @[https://medium.com/serverless-transformation/what-a-typical-100-serverless-architecture-looks-like-in-aws-40f252cd0ecb]
[[}]]


● EXAMPLE DATA STORE ARCHITECTURE:
- Mix data store model based on:
  └ Document store:
    - MongoDB        : Store and manage objects directly as documents, keeping their structure intact.
                       Avoiding Object Relational Mapping in RDMS.
    - MongoDB-GridFS : storage system supports efficient querying and storage of binary files.
                       (videos, ...). Avoid the need fo blob storage structures.
  └ Graph database ("Hyper-relational" ddbb)
    - Neo4j          : Allows for complex queries for highly linked data, stored data as nodes and links.

  └ Spring Data module repositories: used to "match" Java codebase with underlying data store.
    - Allows mapping java objects to MongoDB with minimal effort.  


● Badoo: dating social network with 20 billion Events/day [[{]]
@[https://www.infoq.com/news/2019/08/badoo-20-billion-events-per-day/]
  - business goal (of the intelligence department): collect,process and report user event information
    to create insights to help the company make formed decisions.
  
  - events go through a lifecycle:
    - Receive: Using Protobuf, events from clients are streamed through LSD, an OOSS streaming daemon
      which is used to filter and route the events.
      ┌─ KEYPOINT: ───────────────────────────────────────────────── 
      │ Badoo batches the data hourly rather than doing so in realtime.
      │ This is because, in the event of failure, Kazanov believes that
      │ re─loading a batch is easier, as it’s simple to compare against
      │ the target database to see if it was written correctly.
      └──────────────────────────────────────────────────────────────
    -   Store: Data is stored in a data lake in ORC file format, running on HDFS.
               (ORC is columnar-orientated, strong compression, supported by multiple applications,
                can be queried using Hive, database on top of Hadoop with SQL-like language).
               Events with schemas are stored in Exasol, a columnar distributed analytics database 
               with SQL query-syntax and able to store terrabytes of data.
    - Process: Data is processed using an "Spark cluster".
    -  Report: "microstrategy" reporting tool is used which allows Exasol to be queried using 
               dashboards and reports. 
               In addition, a custom tool called CubeDB is used, designed to run queries faster 
               for technical reporting.
  
  PRE-SETUP:
  1) business analyst creates a schema for a given event.
  2) From this schema Protobuf client libraries are generated for various platforms.

[[}]]

● Logging@Coinbase [[{]]
@[https://www.infoq.com/news/2019/02/metrics-logging-coinbase]

 INITIALLY:                  -> moved to··············>  FINAL VERSION:
 SELF-MANAGED ELK CLUSTER                                MANAGED-AWS-ELK:
 - log-analysis                                          -  log aggregation
 - metrics-visualization                                 DATADOG
                                                         - metrics collection 

 PROBLEMS:                                               SOLUTIONS:
 - Load peaks required cluster's restarts.               - AWS's managed Elasticsearch is logically sharded
 - vulnerable to expensive queries.                        by use case using an nginx proxy in front, solving 
 - It was also impossible to collect diagnostic            the problem of scalability, routing requests to
   data unless the cluster was restarted.                  the correct Kibana dashboard based on the incoming
 - The team discovered that the largest applications       request, and also performs authentication against
   were responsible for consuming the most ELK capacity,   Coinbase’s internal single sign-on (SSO) service.
   forced to reduce the log retention period.
 - alerting solutions like ElastAlert and Watcher that 
   work off ElasticSearch "don't allow engineers to 
   interactively build alerts" and were difficult to 
   integrate with third party tools.


(AWS Cloudwatch does expose OS metrics, but these would have been
 available in a separate dashboard from the custom metrics)

- For Datadog the team added some security barriers like building their own Docker container (vs 
  provided one) or running on a separate network bridge.
  
- THE TEAM ALSO WRAPPED THE STANDARD DOCKER SOCKET WITH A PROXY TO PREVENT 
  POSSIBLE ACCESS TO ENVIRONMENT VARIABLES BY THE AGENT.

- The Coinbase team defined service level indicators (SLIs) around the new metrics,
  with the relevant time series graphs for each.

... However, it is not clear how the correlation between logs and metrics happen,
 since they are collected by different third party services.
[[}]]


- An Introduction to Time Series with Team Apache [[{]]
  https://www.safaribooksonline.com/library/view/an-introduction-to/9781491934951/
  Apache Cassandra evangelist Patrick McFadin shows how to solve time-series data
  problems with technologies from Team Apache: Kafka, Spark and Cassandra.
  - Kafka: handle real-time data feeds with this "message broker"
  - Spark: parallel processing framework that can quickly and efficiently
           analyze massive amounts of data.
  - Spark Streaming: perform effective stream analysis by ingesting data
           in micro-batches.
  - Cassandra: distributed database where scaling and uptime are critical
  - Cassandra Query Language (CQL): navigate create/update your data and data-models
  - Spark+Cassandra: perform expressive analytics over large volumes of data

● LinkedIn Marketing Versioned API Framework:
https://www.infoq.com/news/2022/08/linkedin-api-versioning/
  - LEGACY ARCHITECTURE:
    various business lines and exposed externally via Rest.li API gateway.
    PROBLEM: The APIs were not versioned and everything implemented for
             the internal APIs was published to the external customers
             directly blocking customers from accessing the latest features
             and causing internal challenges with new feature development.

    "allow external partners to migrate to newer versions at their own pace"

  - NEW ARCHITECTURE:
    Each API-product exposes its versioned models and APIs through a 
    mid-tier that serves APIs for external partners to effectively
    isolate external applications from changes and allow partners
    to migrate to new versions at their own pace.
    Whenever an external application requests a specific API version,
    the API gateway translates the request and forwards it to the
    appropriate mid-tier.

    "..  Like any other API gateway, it brings authentication,
      request Mapping, throttling control, authorization, anti-abuse
      control, and request dispatching..."

    - To avoid services having to maintain version-specific logic 
      in code the "VERSIONING EXECUTION FRAMEWORK" LIBRARY was 
      created to:
      STEP 1) convert requests to the latest possible version via 
         USER-DEFINED TRANSFORMATION.
      STEP 2) convert STEP 1) output to the latest available
         internal model via the USER-DEFINED INTERNAL MODEL CONVERTER.
[[}]]
